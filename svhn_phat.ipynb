{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import rfm_q\n",
    "importlib.reload(rfm_q)  # Reload the updated module\n",
    "from rfm import *\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import Aer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import csv\n",
    "import scipy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import hickle\n",
    "from numpy.linalg import solve\n",
    "import time\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_machine_learning.state_fidelities import BaseStateFidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(torchset,n_samples,num_classes=10):\n",
    "    indices = list(np.random.choice(len(torchset),n_samples))\n",
    "\n",
    "    trainset = []\n",
    "    for ix in indices:\n",
    "        x,y = torchset[ix]\n",
    "        ohe_y = torch.zeros(num_classes)\n",
    "        ohe_y[y] = 1\n",
    "        trainset.append(((x/np.linalg.norm(x)).reshape(-1),ohe_y))\n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 16)\n",
      "(50, 16)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('MNIST_4x4/4x4MNIST_Train&Test/MNIST_Train_Nox16.mat')\n",
    "test_data = scipy.io.loadmat('MNIST_4x4/4x4MNIST_Train&Test/MNIST_Test_Nox16.mat')\n",
    "\n",
    "X_train = train_data['VV'][:50]\n",
    "X_test = test_data['UU'][:50]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "csv_file_path1 = 'MNIST_4x4/4x4MNIST_Train&Test/mnist_train.csv'\n",
    "csv_file_path2 = 'MNIST_4x4/4x4MNIST_Train&Test/mnist_test.csv'\n",
    "\n",
    "# Open the CSV file in read mode.\n",
    "with open(csv_file_path1, newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "\n",
    "    for row in csvreader:\n",
    "        if row:  \n",
    "            y_train.append(int(row[0]))\n",
    "\n",
    "with open(csv_file_path2, newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "\n",
    "    for row in csvreader:\n",
    "        if row:  \n",
    "            y_test.append(int(row[0]))\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np.eye(num_classes)[y_train[:50]]\n",
    "y_test = np.eye(num_classes)[y_test[:50]]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, labels = batch\n",
    "        X_list.append(inputs)\n",
    "        y_list.append(labels)\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    y = torch.cat(y_list, dim=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(X):\n",
    "    \"\"\"Scales each column of X to [0, 1] then multiplies by pi.\"\"\"\n",
    "    X = X.copy().astype(np.float64)  # ensure float type\n",
    "    for j in range(X.shape[1]):\n",
    "        col_min = X[:, j].min()\n",
    "        col_max = X[:, j].max()\n",
    "        if abs(col_max - col_min) < 1e-12:\n",
    "            X[:, j] = 0.0\n",
    "        else:\n",
    "            X[:, j] = (X[:, j] - col_min) / (col_max - col_min)\n",
    "    X *= np.pi\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_kernel_batches(x_vec, y_vec, batch_size, is_symmetric, evaluate_duplicates):\n",
    "    n_x, n_y = x_vec.shape[0], y_vec.shape[0]\n",
    "    current_batch = []\n",
    "    batch_count = 0\n",
    "\n",
    "    def generator():\n",
    "        nonlocal current_batch, batch_count\n",
    "        for i in range(n_x):\n",
    "            js = range(i, n_y) if is_symmetric else range(n_y)\n",
    "            for j in js:\n",
    "                if evaluate_duplicates == \"off_diagonal\" and is_symmetric and i == j:\n",
    "                    continue\n",
    "                if evaluate_duplicates == \"none\" and np.array_equal(x_vec[i], y_vec[j]):\n",
    "                    continue\n",
    "                current_batch.append((i, j, x_vec[i], y_vec[j]))\n",
    "                if len(current_batch) == batch_size:\n",
    "                    batch_count += 1\n",
    "                    yield current_batch\n",
    "                    current_batch = []\n",
    "        if current_batch:\n",
    "            batch_count += 1\n",
    "            yield current_batch\n",
    "\n",
    "    # Materialize all batches to count them\n",
    "    all_batches = list(generator())\n",
    "    return iter(all_batches), batch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kernel_matrix(x_vec, y_vec, feature_map, fidelity, enforce_psd=True, evaluate_duplicates=\"off_diagonal\", batch_size=256):\n",
    "    if y_vec is None:\n",
    "        y_vec = x_vec\n",
    "        is_symmetric = True\n",
    "    else:\n",
    "        is_symmetric = np.array_equal(x_vec, y_vec)\n",
    "\n",
    "    n_x, n_y = x_vec.shape[0], y_vec.shape[0] # n_x, n_x is num sample at this point\n",
    "    kernel_matrix = np.ones((n_x, n_y))\n",
    "\n",
    "    print(f\"kernel_matrix shape: {kernel_matrix.shape}\")\n",
    "    # Get batch generator and total count\n",
    "    batch_gen, total_batches = make_kernel_batches(x_vec, y_vec, batch_size, is_symmetric, evaluate_duplicates)\n",
    "\n",
    "    # Process batches with tqdm progress bar\n",
    "    for batch in tqdm(batch_gen, total=total_batches, desc=\"[Quantum Kernel Eval]\"):\n",
    "        i_indices, j_indices, lefts, rights = zip(*batch)\n",
    "        lefts = np.array(lefts)\n",
    "        rights = np.array(rights)\n",
    "\n",
    "        job = fidelity.run(\n",
    "            [feature_map] * len(batch),\n",
    "            [feature_map] * len(batch),\n",
    "            lefts,\n",
    "            rights\n",
    "        )\n",
    "        results = job.result().fidelities\n",
    "\n",
    "        for k in range(len(batch)):\n",
    "            i, j = i_indices[k], j_indices[k]\n",
    "            kernel_matrix[i, j] = results[k]\n",
    "            if is_symmetric:\n",
    "                kernel_matrix[j, i] = results[k]\n",
    "\n",
    "    if is_symmetric and enforce_psd:\n",
    "        eigvals, eigvecs = np.linalg.eigh(kernel_matrix)\n",
    "        eigvals = np.clip(eigvals, 0, None)\n",
    "        kernel_matrix = eigvecs @ np.diag(eigvals) @ eigvecs.T\n",
    "\n",
    "    return kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantum_kernel_matrix(X1, X2, q_kernel, M=None, do_encode=True):\n",
    "    \"\"\"\n",
    "    Evaluates the quantum kernel matrix for inputs X1 and X2.\n",
    "    Applies optional encoding and a linear transformation via M.\n",
    "    \"\"\"\n",
    "    if isinstance(X1, torch.Tensor):\n",
    "        X1 = X1.cpu().numpy()\n",
    "    if isinstance(X2, torch.Tensor):\n",
    "        X2 = X2.cpu().numpy()\n",
    "\n",
    "    if do_encode:\n",
    "        X1 = encode_features(X1)\n",
    "        X2 = encode_features(X2)\n",
    "\n",
    "    if M is not None:\n",
    "        sqrtM = np.real_if_close(np.linalg.cholesky(M))\n",
    "        X1 = X1 @ sqrtM\n",
    "        X2 = X2 @ sqrtM\n",
    "\n",
    "    print(f\"Input X1 shape: {X1.shape}\")\n",
    "    print(f\"Input X2 shape: {X2.shape}\")\n",
    "\n",
    "    feature_map = q_kernel.feature_map\n",
    "    fidelity = q_kernel.fidelity\n",
    "    print(\"[DEBUG] Evaluating Quantum Kernel...\")\n",
    "    start_time = time.time()\n",
    "    K = evaluate_kernel_matrix(x_vec=X1, y_vec=X2, feature_map=feature_map, fidelity=fidelity)\n",
    "    end_time = time.time()\n",
    "    print(f\"[DEBUG] Kernel evaluated: shape {K.shape}, time {end_time - start_time:.2f} s\")\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_rfm(train_loader, test_loader,\n",
    "          iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "          train_acc=False, loader=True, classif=True):\n",
    "    print(\"[DEBUG] Entered q_rfm function...\")\n",
    "    \n",
    "    # Use dummy training data to set the feature dimension\n",
    "    X_train_dummy, _ = get_data(train_loader) if loader else train_loader\n",
    "    feature_dim = X_train_dummy.shape[1]\n",
    "    feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement=\"full\")\n",
    "    \n",
    "    print(\"[DEBUG] Creating FidelityQuantumKernel...\")\n",
    "    q_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    print(\"[DEBUG] FidelityQuantumKernel created successfully\")\n",
    "\n",
    "    if loader:\n",
    "        print(\"[DEBUG] Loaders provided\")\n",
    "        X_train, y_train = get_data(train_loader)\n",
    "        X_test, y_test = get_data(test_loader)\n",
    "    else:\n",
    "        print(\"[DEBUG] Loaders not used, loading manually\")\n",
    "        X_train, y_train = train_loader\n",
    "        X_test, y_test = test_loader\n",
    "        X_train = torch.from_numpy(X_train).float()\n",
    "        X_test = torch.from_numpy(X_test).float()\n",
    "        y_train = torch.from_numpy(y_train).float()\n",
    "        y_test = torch.from_numpy(y_test).float()\n",
    "    \n",
    "    print(f\"[DEBUG] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"[DEBUG] X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    feature_dim = X_train.shape[1]\n",
    "    feature_map.feature_dimension = feature_dim\n",
    "\n",
    "    for i in range(iters):\n",
    "        print(f\"[DEBUG] Iteration {i+1}/{iters} started...\")\n",
    "        print(\"[DEBUG] Computing K_train...\")\n",
    "        K_train = quantum_kernel_matrix(X_train, X_train, q_kernel)\n",
    "        print(f\"[DEBUG] K_train computed, shape: {K_train.shape}\")\n",
    "        sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "        \n",
    "        if train_acc:\n",
    "            preds = (sol @ K_train).T\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "        \n",
    "        K_test = quantum_kernel_matrix(X_train, X_test, q_kernel)\n",
    "        preds = (sol @ K_test).T\n",
    "        mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", mse)\n",
    "        \n",
    "        if classif:\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_test, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "\n",
    "    return mse, K_train, K_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Entered q_rfm function...\n",
      "[DEBUG] Creating FidelityQuantumKernel...\n",
      "[DEBUG] FidelityQuantumKernel created successfully\n",
      "[DEBUG] Loaders provided\n",
      "[DEBUG] X_train shape: torch.Size([50, 16]), y_train shape: torch.Size([50, 10])\n",
      "[DEBUG] X_test shape: torch.Size([50, 16]), y_test shape: torch.Size([50, 10])\n",
      "[DEBUG] Iteration 1/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "Input X1 shape: (50, 16)\n",
      "Input X2 shape: (50, 16)\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "kernel_matrix shape: (50, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Quantum Kernel Eval]:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Quantum Kernel Eval]: 100%|██████████| 5/5 [16:38<00:00, 199.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Kernel evaluated: shape (50, 50), time 998.61 s\n",
      "[DEBUG] K_train computed, shape: (50, 50)\n",
      "Round 0 Train Acc:  1.0\n",
      "Input X1 shape: (50, 16)\n",
      "Input X2 shape: (50, 16)\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "kernel_matrix shape: (50, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Quantum Kernel Eval]: 100%|██████████| 10/10 [33:58<00:00, 203.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Kernel evaluated: shape (50, 50), time 2039.21 s\n",
      "Round 0 MSE:  0.09851583488029791\n",
      "Round 0 Acc:  0.34\n",
      "[DEBUG] Iteration 2/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "Input X1 shape: (50, 16)\n",
      "Input X2 shape: (50, 16)\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "kernel_matrix shape: (50, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Quantum Kernel Eval]: 100%|██████████| 5/5 [16:37<00:00, 199.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Kernel evaluated: shape (50, 50), time 997.78 s\n",
      "[DEBUG] K_train computed, shape: (50, 50)\n",
      "Round 1 Train Acc:  1.0\n",
      "Input X1 shape: (50, 16)\n",
      "Input X2 shape: (50, 16)\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "kernel_matrix shape: (50, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Quantum Kernel Eval]:  80%|████████  | 8/10 [28:17<07:04, 212.40s/it]"
     ]
    }
   ],
   "source": [
    "# Convert to torch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders.\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Run q_rfm on dummy data to test MSE and accuracy.\n",
    "mse_final, K_train, K_test = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True, train_acc=True)\n",
    "print(f\"Final MSE from q_rfm on 4x4 data: {mse_final}\")\n",
    "print(f\"K_train shape: {K_train.shape}\")\n",
    "print(f\"K_test shape: {K_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce number of classes\n",
    "Reduce to 20 samples (20 train, 5 test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
